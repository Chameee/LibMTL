{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f55a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from create_dataset_v2 import CustomDataset, ToNumpyArray\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa1a4e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTLInfluencer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        #self.net = models.resnet18(pretrained=True)\n",
    "        #self.n_features = self.net.fc.in_features\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.net.fc = nn.Identity()\n",
    "    \n",
    "         \n",
    "        self.shared_encoder =  nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.accept_decoder = nn.Sequential(\n",
    "            nn.Linear(output_size, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.revenue_decoder = nn.Sequential(\n",
    "            nn.Linear(output_size, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.reputation_decoder = nn.Sequential(\n",
    "            nn.Linear(output_size, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        encoded_x = self.shared_encoder(x)\n",
    "        accept_head = self.accept_decoder(encoded_x)\n",
    "#         revenue_head = self.revenue_decoder(encoded_x)\n",
    "#         reputation_head = self.reputation_decoder(encoded_x)\n",
    "#         return accept_head, revenue_head, reputation_head\n",
    "        return accept_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d33b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n",
      "See Feature Shape: (183283, 140)\n",
      "done loading data!\n"
     ]
    }
   ],
   "source": [
    "all_file = 'acc_v6.csv'\n",
    "#     train_file = 'acc_v2.csv'\n",
    "#     test_file = 'acc_v2.csv'\n",
    "batch_size = 64\n",
    "input_size = 140\n",
    "encoder_hidden_size = 64\n",
    "encoder_output_size = 32\n",
    "decoder_hidden_size = 32\n",
    "n_epochs = 30\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device\", device)\n",
    "\n",
    "all_dataset = CustomDataset(all_file)\n",
    "#     train_dataset = CustomDataset(train_file)\n",
    "#     test_dataset = CustomDataset(test_file)\n",
    "train_size = int(0.8 * len(all_dataset))\n",
    "test_size = len(all_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset=all_dataset, lengths=[train_size, test_size], generator=torch.manual_seed(0))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"done loading data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bad0c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_list = []\n",
    "acc_train_list = []\n",
    "for data in test_dataset:\n",
    "    _, acc, _, _ = data\n",
    "    acc_test_list.append(acc)\n",
    "for data in train_dataset:\n",
    "    _, acc, _, _ = data\n",
    "    acc_train_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e622807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([31001,  5656]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(acc_test_list).reshape(1,-1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67cc2c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([123481,  23145]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(acc_train_list).reshape(1,-1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f45cd132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146626"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d43d3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, b1 = torch.utils.data.random_split(dataset=all_dataset, lengths=[train_size, test_size], generator=torch.manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed259fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146626"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc0d6c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36657"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be200c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8d9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    all_file = 'acc_v6.csv'\n",
    "#     train_file = 'acc_v2.csv'\n",
    "#     test_file = 'acc_v2.csv'\n",
    "    batch_size = 64\n",
    "    input_size = 140\n",
    "    encoder_hidden_size = 64\n",
    "    encoder_output_size = 32\n",
    "    decoder_hidden_size = 32\n",
    "    n_epochs = 30\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"device\", device)\n",
    "    \n",
    "    all_dataset = CustomDataset(all_file)\n",
    "#     train_dataset = CustomDataset(train_file)\n",
    "#     test_dataset = CustomDataset(test_file)\n",
    "    train_size = int(0.8 * len(all_dataset))\n",
    "    test_size = len(all_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset=all_dataset, lengths=[train_size, test_size], generator=torch.manual_seed(0))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(\"done loading data!\")\n",
    "    \n",
    "    model = MTLInfluencer(input_size, encoder_hidden_size, encoder_output_size).to(device=device)\n",
    "\n",
    "    accept_loss = nn.BCELoss()\n",
    "    revenue_loss = nn.MSELoss()\n",
    "    reputation_loss = nn.MSELoss()\n",
    "    sig = nn.Sigmoid()\n",
    "\n",
    "    optimizer  = optim.Adam(model.parameters(), lr=1e-4)  \n",
    "    \n",
    "        # Training loop\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_training_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            x_batch, y1_batch, y2_batch, y3_batch = batch\n",
    "            inputs = x_batch.to(device=device)\n",
    "\n",
    "            accept_label = y1_batch.to(device=device)\n",
    "            revenue_label = y2_batch.to(device=device)\n",
    "            reputation_label = y3_batch.to(device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             accept_output, revenue_output, reputation_output = model(inputs)\n",
    "            accept_output = model(inputs)\n",
    "\n",
    "            loss_1 = accept_loss(sig(accept_output), accept_label)\n",
    "#             loss_2 = revenue_loss(sig(revenue_output.cpu()), revenue_label)\n",
    "#             loss_3 = reputation_loss(sig(reputation_output.cpu()), reputation_label)\n",
    "\n",
    "#             loss = loss_1 + loss_2 + loss_3\n",
    "            loss = loss_1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_training_loss += loss\n",
    "                    # Print loss\n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, n_epochs, i+1, len(train_loader), loss))\n",
    "\n",
    "    # Save ckpt\n",
    "    torch.save(model.state_dict(), './saved_model.pkl')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y1_predict_array = []\n",
    "        y1_label_array = []\n",
    "\n",
    "        y2_predict_array = []\n",
    "        y2_label_array = []\n",
    "\n",
    "        y3_predict_array = []\n",
    "        y3_label_array = []\n",
    "        for batch in test_loader:\n",
    "            x_batch2, y1_batch, y2_batch, y3_batch = batch\n",
    "            x_batch2 = x_batch2.to(device=device)\n",
    "#             accept_output, revenue_output, reputation_output = model(x_batch2)\n",
    "            accept_output = model(x_batch2)\n",
    "\n",
    "#             predicted_accept = accept_output.argmax(dim=1)\n",
    "#             predicted_revenue = revenue_output.argmax(dim=1)\n",
    "#             predicted_reputation = reputation_output.argmax(dim=1)\n",
    "\n",
    "\n",
    "            accept_output_cut = [1 if y > 0 else 0 for y in accept_output]\n",
    "#             revenue_output_cut = [1 if y > 0 else 0 for y in revenue_output]\n",
    "#             reputation_output_cut = [1 if y > 0 else 0 for y in reputation_output]\n",
    "            \n",
    "            y1_predict_array.extend(accept_output_cut)\n",
    "            y1_label_array.extend(y1_batch.reshape(1,-1).tolist()[0])\n",
    "\n",
    "#             y2_predict_array.extend(revenue_output)\n",
    "#             y2_label_array.extend(y2_batch.reshape(1,-1).tolist()[0])\n",
    "\n",
    "#             y3_predict_array.extend(reputation_output)\n",
    "#             y3_label_array.extend(y3_batch.reshape(1,-1).tolist()[0])\n",
    "\n",
    "        accuracy_accept = accuracy_score(y_true=y1_label_array, y_pred=y1_predict_array)\n",
    "        precision_score_accept = precision_score(y_true=y1_label_array, y_pred=y1_predict_array)\n",
    "        recall_score_accept = recall_score(y_true=y1_label_array, y_pred=y1_predict_array)\n",
    "        f1_score_accept = f1_score(y_true=y1_label_array, y_pred=y1_predict_array)\n",
    "        print('y1 Accuracy, precision, recall, f1 of accept: {:.2f} {:.2f} {:.2f} {:.2f}'.format(accuracy_accept, precision_score_accept, recall_score_accept, f1_score_accept))\n",
    "\n",
    "\n",
    "#         mse_revenue = mean_squared_error(y_true=y2_label_array, y_pred=y2_predict_array)\n",
    "#         r2_revenue = r2_score(y_true=y2_label_array, y_pred=y2_predict_array)\n",
    "#         print('y2 MSE, R2: {:.2f} {:.2f}'.format(mse_revenue, r2_revenue))\n",
    "\n",
    "\n",
    "#         mse_reputation = mean_squared_error(y_true=y3_label_array, y_pred=y3_predict_array)\n",
    "#         r2_reputation = r2_score(y_true=y3_label_array, y_pred=y3_predict_array)\n",
    "#         print('y3 MSE, R2: {:.2f} {:.2f}'.format(mse_reputation, r2_reputation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
